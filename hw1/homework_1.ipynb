{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b617ca0-3a0b-4055-abde-4670d18f7270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd122f9-b432-4908-9724-b25f14158f56",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d8523-70b5-478c-8e78-30b113e2c8e7",
   "metadata": {},
   "source": [
    "**IMPORTANT**: When finished all problems, rerun your entire notebook by clicking `Kernel > Restart Kernel and Run All Cells` to make sure your notebook runs correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c171e-c675-4704-b8fb-e4f790e6a453",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Sequential Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30b2cab-38d8-4749-9861-2fa1bf54eed5",
   "metadata": {},
   "source": [
    "In this problem, you will implement a system that labels objects in binary images and compute their geometric properties.\n",
    "\n",
    "Let's first load our sample image and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde57cbd-c3e5-412a-8268-0a479aaef81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread('data/many_objects_2.png')\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463793ed-35d7-47d0-94af-b71e5fa59b04",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1a. Image Binarization (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2545517f-7666-4059-8aa3-72f156dfee0a",
   "metadata": {},
   "source": [
    "Implement the following function that converts a grayscale image to a binary one by thresholding the pixel intensities. Each element in the output array must be a Boolean value where `True` indicates that the intensity of the corresponding pixel in the input is greater than or equal to the threshold value. You should be able to implement this without using `for`-loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d631be-4bca-4eab-a32b-654327fb5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(gray_img, thresh_val):\n",
    "    \"\"\"Converts a grayscale image to a binary image by thresholding.\n",
    "    \n",
    "    Args:\n",
    "    - gray_img: H x W array representing a grayscale image.\n",
    "    - thresh_val: Threshold value.\n",
    "    \n",
    "    Returns:\n",
    "    - binary_img: H x W Boolean array representing the thresholded image.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return binary_img\n",
    "\n",
    "binary_img = binarize(img, thresh_val=0.5)\n",
    "\n",
    "plt.imshow(binary_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e585b6-c298-4569-87dd-1d0be361a02f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1b. Label Connected Regions (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6665f-b4c6-4068-835f-64c3ef519bf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Implement the sequential labeling algorithm in the following function. The function takes a binary image as input and returns an array of the same size. The output array should have data type `int`, where each element is an object label. For example, all background pixels have value 0, all pixels of object 1 has value 1, etc.\n",
    "\n",
    "Recall from the slides that you may want to do the labeling in two passes. In the first pass, pixels are assigned labels based on the labels of their neighbors. (Be careful when handling pixels near the image boundaries.) This labeling process may result in the same area having multiple labels, which is resolved in the second pass. You are free to choose how to resolve equivalent labels. The union-find data structure is especially suitable for this purpose. If you want to implement helper classes or functions, feel free to add them outside the function body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66c230-d560-4ad2-88d5-3e80fccc3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(binary_img):\n",
    "    \"\"\"Label disconnected regions in a binary image.\n",
    "    \n",
    "    Args:\n",
    "    - binary_img: H x W Boolean array representing a binary image where `False`\n",
    "        indicates background while `True` indicates object regions.\n",
    "    \n",
    "    Returns:\n",
    "    - label_img: H x W int array representing an image with labeled object\n",
    "        regions where 0 indicates the background while other values represent\n",
    "        object labels.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return label_img\n",
    "\n",
    "label_img = label(binary_img)\n",
    "plt.matshow(label_img)\n",
    "plt.show()\n",
    "\n",
    "obj_count = len(np.unique(label_img)) - 1\n",
    "print(f\"Found {obj_count} objects in image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab32ba-dbce-43d8-bf9b-edd70b87a6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1c. Calculate Geometric Attributes (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793914f-8b96-4c52-815a-91c98b5e30ae",
   "metadata": {},
   "source": [
    "In the cell below, calculate the geometric attributes (center, orientation, second moment) of each object. A code snippet has been provided to visualize these attributes. To be specific, for each object, we mark the center of the object, and draws an ellipse having the same orientation and second moments around the center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03541f27-881f-42c0-8af2-7479aa430dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "\n",
    "def calculate_geometric_attributes(label_img, label):\n",
    "    \"\"\"Find the geometric attributes of an object in a labeled image.\n",
    "    \n",
    "    The origin of the coordinate system is at the top left corner of the image.\n",
    "    The x axis points to the right. The y axis points down.\n",
    "    \n",
    "    Args:\n",
    "    - label_img: H x W int array representing an image with labeled object\n",
    "        regions where 0 indicates the background while other values represent\n",
    "        object labels.\n",
    "    - label: Label of the object for which we want to calculate the geometric\n",
    "        attributes.\n",
    "        \n",
    "    Returns:\n",
    "    - cx, cy: xy coordinates of the object center.\n",
    "    - theta: Orientation of the object in radians.\n",
    "    - emin, emax: Second moments of the object.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return cx, cy, theta, emin, emax\n",
    "\n",
    "    \n",
    "plt.imshow(img, cmap='gray')\n",
    "labels = [l for l in np.unique(label_img) if l]\n",
    "for label in labels:\n",
    "    cx, cy, t, e1, e2 = calculate_geometric_attributes(label_img, label)\n",
    "    \n",
    "    # Visualization.\n",
    "    # Plot the center of the area.\n",
    "    plt.plot(cx, cy, marker='o', markersize=5, color=(1,0,0))\n",
    "    # Plot an ellipse having the same orientation and second moments as the area.\n",
    "    ew = 2 * ((4/np.pi)**(1/4)) * (e1**(-1/8)) * (e2**(3/8))\n",
    "    eh = ew * np.sqrt(e1 / e2)\n",
    "    plt.gca().add_patch(Ellipse((cx, cy), ew, eh, t*180/np.pi,\n",
    "        facecolor='none', edgecolor=(1,0,0), linewidth=1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e63b37-35a4-4771-88c8-b3dbe7ca406e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Hough Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2621e394-f540-493b-a357-2b9524016089",
   "metadata": {},
   "source": [
    "In this example you will implement the Hough transform to find coins in the sample image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee65f03-4e94-4e64-8ba9-57ef6c230405",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/coins.png')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40584ec4-4d26-4571-8056-5fa5b9558886",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2a. Edge Detection (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ebdb9c-518b-4e60-b85e-602b651ac036",
   "metadata": {},
   "source": [
    "Detect edges in the sample image. Since you have implemented edge detection from scratch in the weekly notebook, here you can simply call `cv2.Canny()`. Pick your threshold values carefully so the edges of the coins are detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae372b6-6bac-40e7-aeb4-50b170b04901",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_img = # TODO\n",
    "plt.imshow(edge_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770fd332-b885-4899-bdb1-7f30f35751a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2b. Hough Transform (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8101bc-a36a-4118-9258-459d99b418c6",
   "metadata": {},
   "source": [
    "Implement the following function to detect circles using the Hough transform. The function should return the accumulator array instead of a list of circles.\n",
    "\n",
    "For simplicity, your implementation can assume that all circles will be fully inside the image and will not be clipped by the image boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e92d5b2-74ec-4092-abf3-6bb8dfbcefc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_circles(edge_img, radii):\n",
    "    \"\"\"Find circles in an image containing edge pixels.\n",
    "    \n",
    "    Args:\n",
    "    - edge_img: H x W uint8 edge image where 0 indictes non-edge pixels\n",
    "        whereas 255 indicates edge pixels.\n",
    "    - radii: A list of R radius values. Only circles whose radius is in this\n",
    "        list will be found.\n",
    "    \n",
    "    Returns:\n",
    "    - score_map: R x W x H accumulator array. `score_map[r_idx, y, x]`\n",
    "        represents the total votes received by the circle of radius\n",
    "        radii[r_idx] centered at pixel `edge_img[y, x]`.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return score_map\n",
    "\n",
    "radii = np.arange(25., 31.)\n",
    "score_map = hough_circles(edge_img, radii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245be3ab-a6b7-4754-83bc-1fdf2a34d432",
   "metadata": {},
   "source": [
    "Visualize the score map (accumulator array) corresponding to `radii[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965ecd8-002b-4900-8e0b-29c4b0b17f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(score_map[0])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb32b1-d552-4d23-90f1-01b7d877c985",
   "metadata": {},
   "source": [
    "From the accumulator array, pick the top scoring circles and display them. It is fine (and expected) if you detect multiple circles for a single coin. We will address this in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7852ab1-c367-4724-959f-07882f8610a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Circle\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "ris, ys, xs = # TODO\n",
    "for ri, y, x in zip(ris, ys, xs):\n",
    "    r = radii[ri]\n",
    "    plt.gca().add_patch(Circle((x, y), r, facecolor='none', edgecolor=(0,1,0), linewidth=2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7257bacf-fd1b-4bf2-8883-ce6e7eb35e2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2c. Non-Maximum Suppression (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202f3fec-be4f-4d90-accc-44990d2d7b1b",
   "metadata": {},
   "source": [
    "You may have observed that your results in the last section contain duplicate detections if you want to detect all coins. This is quite common in detection systems including the neural network detectors that we will cover in the second half of this course. A post-processing step called non-maximum suppression is often needed to remove these duplicate detections. In our case, if two circles overlap with each other too much, we can assume they are duplicate detections and discard the one with lower votes. For the entire list of detections, we could sort them based on votes and repeat this process to suppress duplicate detections.\n",
    "\n",
    "In the cell below, implement this process and plot the results after post-processing. The final results should contain all coins without duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee88eb3-fe2b-4ccd-97e4-8b89b8ce5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
